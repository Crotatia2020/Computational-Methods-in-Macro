{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Solving Rational Expectations Models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Assuming the economic model at hand has a recursive structure, we can turn a sequential problem (SP) into a functional equation (FE). Intuitively, this reformulation of the problem allow us to turn a problem of finding a solution to infinite unkowns in an infinite number of equations (SP), into a problem of finding a finite number of functions in an infinite function space (FE)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Value Function"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let $x$ be the deterministic state space and $s$ stochastic state space: \n",
    "\n",
    "- **Deterministic case**\n",
    "$$ V (x) = \\max_{x^\\prime} [u(x, x^\\prime) + \\beta V (x^\\prime)]  $$\n",
    "\n",
    "This value function has an associated decision rule $g : R^+ \\rightarrow R^+: x^\\prime =g(x)$\n",
    "\n",
    "- **Stochastic case**\n",
    "$$ V (x, s) = \\max_{x^\\prime} [u(x, x^\\prime, s) + \\beta E_{s^\\prime} V (x^\\prime, s^\\prime)]  $$\n",
    "\n",
    "This value function has an associated decision rule $g : R^+ \\times R \\rightarrow R^+: x^\\prime =g(x, s)$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Expressing the model as a value function problem is convenient for several reasons. First, we have many results about the properties of value functions and the decision rules associated with them (for example, regarding their differentiability). These results can be put to good use both in the economic analysis of the problem and in the design of numerical methods. The second reason is that, as a default, we can use value function iteration (explained later in the notebook), a solution method that is particularly reliable, although often slow."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Euler Equation (FOCs)\n",
    "\n",
    "We have outlined several reasons why casting the problem in terms of a value function is attractive. Unfortunately, this formulation can be difficult. If the model does not satisfy the two fundamental welfare theorems, we cannot easily move between the social planner’s problem and the competitive equilibrium. In that case, also, the value function of the household and firms will require laws of motion for individual and aggregate state variables that can be challenging to characterize."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "An alternative is to work directly with the set of equilibrium conditions of the model. These include the first-order conditions for households, firms, and, if specified, government, budget and resource constraints, market clearing conditions, and laws of motion for exoge- nous processes. Since, at the core of these equilibrium conditions, we will have the Euler equations for the agents in the model that encode optimal behavior (with the other condi- tions being somewhat mechanical), this approach is commonly known as the Euler equation method (sometimes also referred to as solving the equilibrium conditions of the models). This solution strategy is extremely general and it allows us to handle non-Pareto efficient economies without further complications."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "In general, when using the first order conditions only, our functional equations, with $x$ being the state space and $x^\\prime=g(x)$ the optimal policy function, boil down to something like:\n",
    "\n",
    "- **Deterministic case**\n",
    "\n",
    "$$ f(x, g(x), g(g(x))) = 0 $$\n",
    "\n",
    "- **Stochastic case**\n",
    "\n",
    "$$ E_{s^\\prime} [f(x, g(x,s), g(g(x,s), s^\\prime), s, s^\\prime)] = 0 $$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Solving Functional Equations Cast In Discrete Time\n",
    "\n",
    "- Log-linear approximation (Local)\n",
    "    - Then use one of the following ways to solve a **linear** rational expectation model:\n",
    "        - Blanchard and Khan (coupling/decoupling)\n",
    "        - Sims (coupling/decoupling exploring expectations errors)\n",
    "        - Uhlig (undetermined coefficients)\n",
    "        \n",
    "- Perturbation (Local, we will note cover this, Dynare great at performing this approach)\n",
    "\n",
    "- Iterative (Global)\n",
    "    - Value function iteration\n",
    "    - Policy function iteration\n",
    "    \n",
    "- Projection (Global)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are some advantages and disadvantages in using each approach. The selection of an approach should depend on the specific application."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Baby Example: Nonstochastic RBC Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\\max_{C_t,K_{t+1}} E_0 \\sum_{t=0}^\\infty \\beta^t \\frac{C_t^{1-\\sigma}}{1-\\sigma}$$\n",
    "\n",
    "subject to:\n",
    "\n",
    "\\begin{align*} C_t + K_{t+1} - (1-\\delta)K_t &= K_t^\\alpha  \\\\\n",
    "K_0 &\\text{ given}\n",
    "\\end{align*}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Value Function or Euler Equation?\n",
    "\n",
    "Since both fundamental welfare theorems hold in this economy, we can jump between the social planner’s problem and the competitive equilibrium according to which approach is more convenient in each moment. In general, this would not be possible, and some care is required to stay on either the equilibrium problem or the social planner’s problem according to the goals of the exercise."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "FOC:\n",
    "\n",
    "$$ C_t^{-\\sigma} - \\beta C_{t+1}^{-\\sigma} [\\alpha K_{t+1}^{\\alpha-1} + (1-\\delta)] = 0$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Which after replacing the budget constraint becomes:\n",
    "\n",
    "$$ [K_t^\\alpha - K_{t+1} + (1-\\delta)K_t]^{-\\sigma} - \\beta [K_{t+1}^\\alpha - K_{t+2} + (1-\\delta)K_{t+1}]^{-\\sigma} [\\alpha K_{t+1}^{\\alpha-1} + (1-\\delta)] = 0$$\n",
    "\n",
    "Hence, we have:\n",
    "\n",
    "\n",
    "$$ f(K_t, K_{t+1}, K_{t+2}) = 0 $$   for $ t = 0,1,2,... $ with $K_0$ given.\n",
    "\n",
    "If the problem has a recursive nature, we will have a time invariant optimal policy function: $K_{t+1} = g(K_t)$ such that:\n",
    "\n",
    "$$ f(K_t, g(K_{t}), g(g(K_{t}))) = 0 $$\n",
    "for all $K_t$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- With only a few rare exceptions this is very hard to solve exactly – Easy cases:\n",
    "    - If $\\sigma = 1$ , $\\delta = 1$ $\\Rightarrow$ $g ( K_t ) = \\alpha \\beta K_t^\\alpha $.\n",
    "    - If $f$ is linear in $K_t, K_{t+1}, K_{t+2}$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Log-linear approximation methods: first-order approximation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 1.\n",
    "\n",
    "Let $\\delta = 0.05$, $\\alpha = 0.3$, $\\beta= 0.99$ and $\\sigma = 1.5$, solve the baby Nonstochastic RBC model\n",
    "using a loglinear approximation around the steady state.\n",
    "\n",
    "a. Solve for the steady state. I.e. solve for the root of $f(K_{ss}, K_{ss}, K_{ss}) = 0$\n",
    "\n",
    "b. Write $f$ in terms of $\\log{K}$. Use $K_t = \\exp{\\log{K_t}}$.\n",
    "\n",
    "c. Linearizing $f$ around the steady-state in logs gets you:\n",
    "\n",
    " $$\\alpha_0 \\log{\\widehat{K}_t} + \\alpha_1  \\log{\\widehat{K}_{t+1}} + \\alpha_2 \\log{\\widehat{K}_{t+2}} = 0 $$,\n",
    " where $\\log{\\widehat{K}} = \\log{K} - \\log{K_{ss}}$. (percentage deviations from steady state)/\n",
    "\n",
    " So, the first thing we need to do is to find the alphas. Note that $\\alpha_0 =\n",
    " \\frac{\\partial f(\\log{K_t}, \\log{K_{t+1}}, \\log{K_{t+2}})}{\\partial \\log{K_t}}$,\n",
    " $\\alpha_1 = \\frac{\\partial f(\\log{K_{t}}, \\log{K_{t+1}}, \\log{K_{t+2}})}{\\partial \\log{K_{t+1}}}$,\n",
    " $\\alpha_2 = \\frac{\\partial f(\\log{K_{t}}, \\log{K_{t+1}}, \\log{K_{t+2}})}{\\partial \\log{K_{t+2}}}$.\n",
    "\n",
    " Compute the numerical derivative of $f$ with respect to log of capital to find all the alphas.\n",
    "\n",
    "d. Use the undetermined coefficients approach to find the solution to $\\log{\\widehat{K}_{t+1}} = g(\\log{\\widehat{K}_t})$.\n",
    "Since loglinearization around the steady state of $f$ turns it into a linear expression, we know that $g$\n",
    "will be linear as well. Hence, we can guess that $\\log{\\widehat{K}_{t+1}} = \\nu \\log{\\widehat{K}_t}$. Substitute this into the loglinear $f$\n",
    " to find that:\n",
    "\n",
    " $$\\alpha_0 \\log{\\widehat{K}_t} + \\alpha_1 \\nu \\log{\\widehat{K}_t} + \\alpha_2 \\nu^2 \\log{\\widehat{K}_t} = 0 $$\n",
    "\n",
    " Given, alphas find $\\nu$ as non-explosive root ($|\\nu|<1$) to the expression above.\n",
    "\n",
    "e. Given $K_0 = 0.98*K^{ss}$, simulate the model for 20 periods. Note that this means $-0.02$ deviation from steady state.\n",
    "\n",
    "f. Simulate the model instead with $\\delta = 1$, $\\alpha = 0.3$, $\\beta= 0.99$ and $\\sigma = 1$ for 20 periods and compare it with the simulation coming from the exact solution: $g ( K_t ) = \\alpha \\beta K_t^\\alpha$. Also, compare the policy functions of the exact solution with the loglinear approximation in a plot."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Iterative Methods: Value Function Iteration"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Well known, basic algorithm of dynamic programming\n",
    "- We have tight convergence properties and bounds on errors \n",
    "- Well suited for parallelization\n",
    "- It will always work (though may be slow)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How Do We Implement The Operator?\n",
    "\n",
    "We come back to our two distinctions: finite versus infinite time and discrete versus continuous state space\n",
    "\n",
    "Then we need to talk about: \n",
    "- Initialization\n",
    "- Discretization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Value Function Iteration in Finite Time \n",
    "\n",
    "We begin with the Bellman operator:\n",
    "\n",
    "$$\\Gamma(V_t(x)) = \\max_{a \\in A(x,t)} u(x, a) + \\beta E V_{t+1} (x^\\prime)  $$\n",
    "\n",
    "\n",
    "- Specify the terminal condition $V_T$:\n",
    "\n",
    "$$ V_{T−1}(x)= \\max_{a \\in A(x,t)} u(x,a)+\\beta E V_T(x^\\prime) $$\n",
    "\n",
    "\n",
    "- Then solve backwards to time 1:\n",
    "\n",
    "$$ V_1(x) = \\max_{a \\in A(x,t)} u(x,a)+\\beta E V_2(x^\\prime) $$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Value Function Iteration in Infinite Time \n",
    "\n",
    "Again, we begin with the Bellman operator:\n",
    "\n",
    "$$\\Gamma(V(x)) = \\max_{a \\in A(x)} u(x, a) + \\beta E V (x^\\prime)$$\n",
    "\n",
    "- Specify the initial guess V_0 and compute:\n",
    "\n",
    "$$V_1(x) = \\max_{a \\in A(x)} u(x, a) + \\beta E V_0 (x^\\prime) $$\n",
    "\n",
    "\n",
    "• Then iterate until convergence:\n",
    "\n",
    "$$V_T(x) = \\max_{a \\in A(x)} u(x, a) + \\beta E V_{T-1} (x^\\prime)  $$\n",
    "\n",
    "until\n",
    "\n",
    "$$ || V_T(x) - V_{T-1}(x)|| < \\epsilon $$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since (FE) is a “contraction mapping” this is guaranteed to converge.\n",
    " \n",
    "- There are many ways of implementing this on a computer\n",
    "\n",
    "- In today’s exercise you will use the “beginner’s algorithm” known as “discretised value function iteration”.\n",
    "\n",
    "But before that let's talk about initialization and discretization."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Initialization\n",
    "\n",
    "- **Finite Time**\n",
    "\n",
    "    - Usually, economics of the problem provides natural choices.\n",
    "    - Example: final value of an optimal expenditure problem is zero.\n",
    "    - However, some times there are subtle issues.\n",
    "    - Example: what is the value of dying? And of bequests? OLG.\n",
    "    \n",
    "- **Infinite Time**\n",
    "\n",
    "    - Theorems tell us we will converge from any initial guess.\n",
    "    - That does not mean we should not be smart picking our initial guess.\n",
    "    - Several good ideas:\n",
    "        1. Steady state of the problem (if one exists). Usually saves at least one iteration. \n",
    "        2. Collapsing one or more dimensions of the problem. Which one?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Discretization\n",
    "\n",
    "- In the case where we have a continuous state space, we need to discretize it into a grid\n",
    "- How do we do that?\n",
    "- Dealing with curse of dimensionality\n",
    "- Do we let future states lie outside the grid?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- The exact problem:\n",
    "\n",
    "$$V(x) = \\max_{a \\in A(x)} u(x, a) + \\beta E V (x^\\prime)  $$\n",
    "\n",
    "\n",
    "- The approximated problem on the computer:\n",
    "\n",
    "$$V(x) = \\max_{a \\in \\hat{A}(x)} u(x, a) + \\beta \\sum_{j=1}^N V (x^\\prime_j) p_j(x^\\prime|x,a) $$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Grid Generation\n",
    "\n",
    "- Huge literature on numerical analysis on how to efficiently generate grids\n",
    "\n",
    "- Two main issues:\n",
    "    1. How to select points sj\n",
    "    2. How to approximate $E$ by $p_N$\n",
    "    \n",
    "    \n",
    "- Answer to second issue follows from answer to first problem\n",
    "- We can (and we will) combine strategies to generate grids\n",
    "\n",
    "**Uniform Grid**\n",
    "\n",
    "- First, decide the number of points in the grid \n",
    "- Distribute them uniformly in the state space \n",
    "- What if the state space is unbounded?\n",
    "\n",
    "- Advantages and disadvantages"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Applying the Algorithm**\n",
    "\n",
    "- After deciding initialization and discretization still need to implement each step:\n",
    "\n",
    "$$V_T(x) = \\max_{a \\in \\hat{A}(x)} u(x, a) + \\beta \\sum_{j=1}^N V_{T-1} (x^\\prime_j) p_j(x^\\prime|x,a) $$\n",
    "\n",
    "- Two numerical operators:\n",
    "    1. Maximization\n",
    "    2. Integration\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Maximization\n",
    "\n",
    "- We need to apply the max operator\n",
    "- Most costly step of value function iteration\n",
    "- All methods search through the space of feasible choices generating a sequence of guesses that converges to the solution\n",
    "- Use a variety of the methods we've already discussed"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Value Function Iteration of the Baby Example: Nonstochastic RBC model "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Exercise 2\n",
    "\n",
    "a. Compute the steady state capital and create a grid for capital, $K = (k_1,k_2,...k_n)$ that starts at $k_1 = 0.9k_{ss}$ and ends at $k_n = 1.1k_{ss}$, where $n=1000$. $k_{ss} = ((1/\\beta-(1-\\delta))/\\alpha)^{(1/(\\alpha-1))}$\n",
    "\n",
    "b. Assume same parameters as with exact solution in exercise 1 (Note: $\\delta=1$, $\\sigma=1$). Guess that $V_0(k)=0$ for all $k \\in K$. Iterate on $V_{n+1} = \\max_{k^\\prime \\in K}{u(k,k^\\prime) + \\beta V_n(k′)}$\n",
    "until convergence. To use brute force optimization of utility notice we need a 2Dimensional grid. Create such a grid. Notice how the choices $k^\\prime$ is restricted to only take on values on the grid. Having a fine grid is important to have a good approximation!\n",
    "\n",
    "d. Find the associated optimal policy function and compare it with the exact solution: $g ( K_t ) = \\alpha \\beta K_t^\\alpha$.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Iterative Methods: Euler Equation Iteration\n",
    "\n",
    "In many problems, we know that $V(k)$ is\n",
    "\n",
    "1. Concave\n",
    "2. Differentiable\n",
    "\n",
    "Hence, the first order conditions are necessary and sufficient.\n",
    "\n",
    "In general, our Euler equation boils down to something like\n",
    "\n",
    "$E_{z'}[f(x,x',x'', z, z')]=0$, for all $x\\in\\chi$ and $z \\in \\mathcal{Z} $.\n",
    "\n",
    "We would like to find a function $x'=g(x,z)$ such that\n",
    "\n",
    "$E_{z'}[f(x,g(x,z),g(g(x,z),z'), z, z')]=0$\n",
    "\n",
    "There are several numerical approaches to find $\\hat{g}\\approx g$, which include:\n",
    "\n",
    "1. Direct\n",
    "2. Fixed point iteration\n",
    "3. Time iteration\n",
    "\n",
    "#### 1. Direct approach\n",
    "\n",
    "Find the root to\n",
    "\n",
    "$E_{z'}[f(x,x',\\hat{g}(x',z'), z, z')]=0$, for all $x\\in\\chi$ and $z \\in \\mathcal{Z} $,\n",
    "subject to the constraint that $\\hat{g}(x,z) = x'$.\n",
    "\n",
    "Very fast! When it works...\n",
    "\n",
    "Not very robust.\n",
    "\n",
    "#### 2. Fixed point iteration\n",
    "\n",
    "Remember chapter 2, we can turn a root finding problem into a fixed point problem:\n",
    "\n",
    "$E_{z'}[f(x,x',\\hat{g}(x',z'), z, z')]=x'-x'$\n",
    "\n",
    "$x'+E_{z'}[f(x,x',\\hat{g}(x',z'), z, z')]=x'$\n",
    "\n",
    "$x'= g_{n+1}(x,z) = g_{n}(x,z)-E_{z'}[f(x,g_{n}(x,z),g_n(g_{n}(x,z),z'), z, z')]$\n",
    "\n",
    "Start with a initial guess for $g_0(k,z)$ and iterate until:\n",
    "\n",
    "$||g_{n+1}-g_n||<\\varepsilon$.\n",
    "\n",
    "Very fast method and does not need derivatives.\n",
    "\n",
    "#### 3. Time iteration\n",
    "\n",
    "Suppose we have a candidate policy function $g_n(k,z)$. Insert $g_n(k,z)$ only to $x''$:\n",
    "\n",
    "$E_{z'}[f(x,x',g_n(x',z'), z, z')]=0$\n",
    "\n",
    "Solve for the root to find $x'$. Update $g_{n+1}=x'$. Iterate until\n",
    "\n",
    "$||E_{z'}[f(x,g_n(x),g_n(g_n(x,z),z'), z, z')]||<\\varepsilon$.\n",
    "\n",
    "It's a contraction mapping.\n",
    "\n",
    "Slower than fixed point iteration (due to root finding procedure).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Exercise 3\n",
    "\n",
    "Recall the Euler equation of the simple RBC model:\n",
    "\n",
    "$$ [K_t^\\alpha - K_{t+1} + (1-\\delta)K_t]^{-\\sigma} - \\beta [K_{t+1}^\\alpha - K_{t+2} + (1-\\delta)K_{t+1}]^{-\\sigma} [\\alpha K_{t+1}^{\\alpha-1} + (1-\\delta)] = 0$$\n",
    "\n",
    "a. Solve the simple RBC model using time iteration using the same parameters as before.\n",
    "\n",
    "b. Compare it with the exact solution: $g ( K_t ) = \\alpha \\beta K_t^\\alpha$.\n",
    "\n",
    "\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "PyCharm (Computational Methods in Macro)",
   "language": "python",
   "name": "pycharm-a2348e21"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}