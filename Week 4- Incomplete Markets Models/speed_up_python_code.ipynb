{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Speed up your Python code\n",
    "## Python is slow\n",
    "Compared to low-level languages, Python is typically faster to write, less error prone and easier to debug. However, Python is much harder to optimize — that is, turn into fast machine code — than languages like C or Fortran. \n",
    "\n",
    "But still, high productivity languages should be chosen over high speed languages for the great majority of scientific computing tasks\n",
    "\n",
    "This is because\n",
    "\n",
    "* Of any given program, relatively few lines are ever going to be time-critical\n",
    "* For those lines of code that are time-critical, we can achieve C-like speed with minor modifications\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's start by trying to understand why high level languages like Python are slower than compiled code\n",
    "## Dynamic typing\n",
    "Consider this Python operation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "20"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a, b = 10, 10\n",
    "a + b"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Even for this simple operation, the Python interpreter has a fair bit of work to do\n",
    "\n",
    "For example, in the statement `a + b`, the interpreter has to know which operation to invoke\n",
    "\n",
    "If `a` and `b` are strings, then `a + b` requires string concatenation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'foobar'"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a, b = 'foo', 'bar'\n",
    "a + b"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If `a` and `b` are lists, then `a + b` requires list concatenation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['foo', 'bar']"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a, b = ['foo'], ['bar']\n",
    "a + b"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We say that the operator `+` is *overloaded* — its action depends on the type of the objects on which it acts.\n",
    "\n",
    "As a result, Python must check the type of the objects and then call the correct operation\n",
    "\n",
    "This involves substantial overheads\n",
    "\n",
    "## Static Types\n",
    "\n",
    "Compiled languages avoid these overheads with explicit, static types\n",
    "\n",
    "For example, consider the following C code, which sums the integers from 1 to 10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```c\n",
    "#include <stdio.h>\n",
    "\n",
    "int main(void) {\n",
    "    int i;\n",
    "    int sum = 0;\n",
    "    for (i = 1; i <= 10; i++) {\n",
    "        sum = sum + i;\n",
    "    }\n",
    "    printf(\"sum = %d\\n\", sum);\n",
    "    return 0;\n",
    "}\n",
    "```\n",
    "\n",
    "The variables `i` and `sum` are explicitly declared to be integers\n",
    "\n",
    "Hence, the meaning of addition here is completely unambiguous"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Access\n",
    "\n",
    "Another drag on speed for high level languages is data access\n",
    "\n",
    "To illustrate, let’s consider the problem of summing some data — say, a collection of integers\n",
    "\n",
    "In the standard Python implementation (CPython), list elements are placed in memory locations that are in a sense contiguous. However, these list elements are more like pointers to data rather than actual data\n",
    "\n",
    "Hence, there is still overhead involved in accessing the data values themselves. This is a considerable drag on speed\n",
    "\n",
    "In fact, it’s generally true that memory traffic is a major culprit when it comes to slow execution\n",
    "\n",
    "Let’s look at some ways around these problems\n",
    "\n",
    "## Vectorization\n",
    "\n",
    "When we run batch operations on arrays as batch operators, the result is C or Fortran-like speed, then the code is *vectorized*\n",
    "\n",
    "**Numpy** is all about vectorization. You'll need to change your way of thinking from procedure to vectors\n",
    "\n",
    "Many functions provided by NumPy are so-called universal functions — also called [*ufuncs*](https://docs.scipy.org/doc/numpy/reference/ufuncs.html) that operate on ndarrays in an element-by-element fashion. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import numpy as np\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The squared sum with 100000 numbers is 33364.051964 in 0.071215 secs\n"
     ]
    }
   ],
   "source": [
    "start = time.time()   # Start timing\n",
    "n = 100_000\n",
    "sum = 0\n",
    "for i in range(n):\n",
    "    x = random.uniform(0, 1)\n",
    "    sum += x**2\n",
    "end = time.time() # End timing\n",
    "\n",
    "print(\"The squared sum with %d numbers is %f in %f secs\"\n",
    "     %(n, sum, end-start))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now compare with the vectorized code\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The squared sum with 100000 numbers is 33364.051964 in 0.003151 secs\n"
     ]
    }
   ],
   "source": [
    "start = time.time()   # Start timing\n",
    "n = 100_000\n",
    "x = np.random.uniform(0, 1, n)\n",
    "np.sum(x**2)\n",
    "end = time.time() # End timing\n",
    "\n",
    "print(\"The squared sum with %d numbers is %f in %f secs\"\n",
    "     %(n, sum, end-start))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Consider the problem of maximizing a function $f$ of two variables $(x,y)$ over the square $[-a, a]\\times[-a, a]$:\n",
    "\n",
    "$f(x,y)=\\frac{cos(x^2+y^2)}{1+x^2+y^2}$ and $a=3$\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The maximum value is 0.999982 in 3.420467 secs\n"
     ]
    }
   ],
   "source": [
    "def f(x, y):\n",
    "    return np.cos(x**2 + y**2) / (1 + x**2 + y**2)\n",
    "\n",
    "grid = np.linspace(-3, 3, 1000)\n",
    "m = -np.inf\n",
    "\n",
    "start = time.time()\n",
    "for x in grid:\n",
    "    for y in grid:\n",
    "        z = f(x, y)\n",
    "        if z > m:\n",
    "            m = z\n",
    "\n",
    "end = time.time()\n",
    "\n",
    "print(\"The maximum value is %f in %f secs\"\n",
    "     %(m, end-start))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And here’s a vectorized version\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The maximum value is 0.999982 in 0.024638 secs\n"
     ]
    }
   ],
   "source": [
    "def f(x, y):\n",
    "    return np.cos(x**2 + y**2) / (1 + x**2 + y**2)\n",
    "\n",
    "grid = np.linspace(-3, 3, 1000)\n",
    "x, y = np.meshgrid(grid, grid)\n",
    "\n",
    "start = time.time()\n",
    "np.max(f(x, y))\n",
    "end = time.time()\n",
    "\n",
    "print(\"The maximum value is %f in %f secs\"\n",
    "     %(m, end-start))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Numba\n",
    "\n",
    "Numba works by generating optimized machine code using the LLVM compiler infrastructure at import time, runtime, or statically (using the included pycc tool). \n",
    "\n",
    "With a few annotations, array-oriented and math-heavy Python code can be just-in-time compiled to native machine instructions, similar in performance to C, C++ and Fortran, without having to switch languages or Python interpreters.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from numba import jit"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Consider some problems that are difficult to vectorize\n",
    "\n",
    "We generate the trajectory of a difference equation given an initial condition\n",
    "\n",
    "Take the difference equation to be the quadratic map: $x_{t+1} = 4x_t(1-x_t)$\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def qm(x0, n):\n",
    "    x = np.empty(n+1)\n",
    "    x[0] = x0\n",
    "    for t in range(n):\n",
    "        x[t+1] = 4 * x[t] * (1 - x[t])\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "qm_numba = jit(qm)  # qm_numba is now a 'compiled' version of qm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "in 0.092340 secs\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "start = time.time()\n",
    "qm(0.1, int(10**5))\n",
    "end = time.time()\n",
    "time1 = end-start\n",
    "print(\"in %f secs\"\n",
    "     %( end-start))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let’s time and compare identical function calls with JIT compilation:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "in 0.000466 secs\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "qm_numba(0.1, int(10**5))\n",
    "end = time.time()\n",
    "time2 = end-start\n",
    "print(\"in %f secs\"\n",
    "     %( end-start))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The first execution is relatively slow because of JIT compilation (see below)\n",
    "\n",
    "Next time and all subsequent times it runs much faster:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The mean value is 0.000000 in 0.000433 secs\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "qm_numba(0.1, int(10**5))\n",
    "end = time.time()\n",
    "time2 = end-start\n",
    "print(\"The mean value is %f in %f secs\"\n",
    "     %(np.mean(x), end-start))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "200.1035366478729"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "time1 / time2  # Calculate speed gain"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is a huge progress relative to how simple and clear the implementation is\n",
    "\n",
    "If you don’t need a separate name for the “numbafied” version of qm, you can just put `@jit` before the function. This is equivalent to `qm = jit(qm)`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "@jit \n",
    "def qm(x0, n):\n",
    "    x = np.empty(n+1)\n",
    "    x[0] = x0\n",
    "    for t in range(n):\n",
    "        x[t+1] = 4 * x[t] * (1 - x[t])\n",
    "    return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Numba for vectorization\n",
    "\n",
    "Numba can also be used to create custom `ufuncs` with the `@vectorize` decorator\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from numba import vectorize\n",
    "\n",
    "@vectorize\n",
    "def f_vec(x, y):\n",
    "    return np.cos(x**2 + y**2) / (1 + x**2 + y**2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The maximum value is 0.999982 in 0.015802 secs\n"
     ]
    }
   ],
   "source": [
    "np.max(f_vec(x, y))  # Run once to compile\n",
    "\n",
    "start = time.time()\n",
    "m = np.max(f_vec(x, y))\n",
    "end = time.time()\n",
    "print(\"The maximum value is %f in %f secs\"\n",
    "     %(m, end-start))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is faster than our vectorized version using NumPy’s ufuncs\n",
    "\n",
    "Why should that be? After all, anything vectorized with NumPy will be running in fast C or Fortran code\n",
    "\n",
    "The reason is that it’s much less memory intensive\n",
    "\n",
    "For example, when NumPy computes np.cos($x**2$ + $y**2$) it first creates the intermediate arrays $x**2$ and $y**2$, then it creates the array np.cos($x**2$ + $y**2$)\n",
    "\n",
    "In our `@vectorize` version using Numba, the entire operator is reduced to a single vectorized process and none of these intermediate arrays are created\n",
    "\n",
    "We can gain further speed improvements using Numba’s automatic parallelization feature by specifying `target=’parallel’`\n",
    "\n",
    "In this case, we need to specify the types of our inputs and outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "@vectorize('float64(float64, float64)', target='parallel')\n",
    "def f_vec(x, y):\n",
    "    return np.cos(x**2 + y**2) / (1 + x**2 + y**2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The maximum value is 0.999982 in 0.007944 secs\n"
     ]
    }
   ],
   "source": [
    "np.max(f_vec(x, y))  # Run once to compile\n",
    "\n",
    "start = time.time()\n",
    "m = np.max(f_vec(x, y))\n",
    "end = time.time()\n",
    "print(\"The maximum value is %f in %f secs\"\n",
    "     %(m, end-start))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cython\n",
    "\n",
    "Like Numba, Cython provides an approach to generating fast compiled code that can be used from Python. As was the case with Numba, a key problem is the fact that Python is dynamically typed\n",
    "\n",
    "As you’ll recall, Numba solves this problem (where possible) by inferring type. Cython’s approach is different — programmers add type definitions directly to their “Python” code. As such, the Cython language can be thought of as Python with type definitions\n",
    "\n",
    "In addition to a language specification, Cython is also a language translator, transforming Cython code into optimized C and C++ code. Cython also takes care of building language extentions — the wrapper code that interfaces between the resulting compiled code and Python"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Suppose that we want to compute the sum $\\sum_{n}^{i=0} \\alpha^i = \\frac{1-\\alpha^{n+1}}{1-\\alpha}$ for given $\\alpha$, $n$\n",
    "\n",
    "Here’s a pure Python function that does the job"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def geo_prog(alpha, n):\n",
    "    current = 1.0\n",
    "    sum = current\n",
    "    for i in range(n):\n",
    "        current = current * alpha\n",
    "        sum = sum + current\n",
    "    return sum"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here’s a C function that will do the same thing\n",
    "\n",
    "```c\n",
    "double geo_prog(double alpha, int n) {\n",
    "    double current = 1.0;\n",
    "    double sum = current;\n",
    "    int i;\n",
    "    for (i = 1; i <= n; i++) {\n",
    "        current = current * alpha;\n",
    "        sum = sum + current;\n",
    "    }\n",
    "    return sum;\n",
    "}\n",
    "```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We’re going to run our Cython code in the Jupyter notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Cython extension is already loaded. To reload it, use:\n",
      "  %reload_ext Cython\n"
     ]
    }
   ],
   "source": [
    "%load_ext Cython"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%%cython\n",
    "def geo_prog_cython(double alpha, int n):\n",
    "    cdef double current = 1.0\n",
    "    cdef double sum = current\n",
    "    cdef int i\n",
    "    for i in range(n):\n",
    "        current = current * alpha\n",
    "        sum = sum + current\n",
    "    return sum"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here cdef is a Cython keyword indicating a variable declaration, and is followed by a type\n",
    "\n",
    "The `%%cython` line at the top is not actually Cython code — it’s a Jupyter cell magic indicating the start of Cython code\n",
    "\n",
    "After executing the cell, you can now call the function ```geo_prog_cython``` from within Python\n",
    "\n",
    "What you are in fact calling is compiled C code with a Python call interface"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The value is 100.000000 in 0.143278 secs\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "v = geo_prog(0.99, int(10**6))\n",
    "end = time.time()\n",
    "print(\"The value is %f in %f secs\"\n",
    "     %(v, end-start))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The value is 100.000000 in 0.053239 secs\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "v = geo_prog_cython(0.99, int(10**6))\n",
    "end = time.time()\n",
    "print(\"The value is %f in %f secs\"\n",
    "     %(v, end-start))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cython with NumPy arrays\n",
    "\n",
    "For problem of generating the iterates of the quadratic map, it iterates and returning a time series requires us to work with arrays. \n",
    "\n",
    "The natural array type to work with is NumPy arrays. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%%cython\n",
    "import numpy as np \n",
    "\n",
    "def qm_cython_first_pass(double x0, int n):\n",
    "    cdef int t\n",
    "    x = np.zeros(n+1, float)\n",
    "    x[0] = x0\n",
    "    for t in range(n):\n",
    "        x[t+1] = 4.0 * x[t] * (1 - x[t])\n",
    "    return np.asarray(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you run this code and time it, you will see that it’s performance is disappointing — nothing like the speed gain we got from Numba"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The mean value is 0.000000 in 0.055337 secs\n",
      "The mean value is 0.000000 in 0.000547 secs\n"
     ]
    }
   ],
   "source": [
    "start1 = time.time()\n",
    "qm_cython_first_pass(0.1, int(10**5))\n",
    "end1 = time.time()\n",
    "print(\"The mean value is %f in %f secs\"\n",
    "     %(np.mean(x), end1-start1))\n",
    "\n",
    "start2 = time.time()\n",
    "qm_numba(0.1, int(10**5))\n",
    "end2 = time.time()\n",
    "print(\"The mean value is %f in %f secs\"\n",
    "     %(np.mean(x), end2-start2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The reason is that working with NumPy arrays incurs substantial Python overheads\n",
    "\n",
    "We can do better by using Cython’s typed `memoryviews`, which provide more direct access to arrays in memory\n",
    "\n",
    "When using them, the first step is to create a NumPy array. Next, we declare a memoryview and bind it to the NumPy array\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%%cython\n",
    "import numpy as np\n",
    "from numpy cimport float_t\n",
    "\n",
    "def qm_cython(double x0, int n):\n",
    "    cdef int t\n",
    "    x_np_array = np.zeros(n+1, dtype=float)\n",
    "    cdef float_t [:] x = x_np_array\n",
    "    x[0] = x0\n",
    "    for t in range(n):\n",
    "        x[t+1] = 4.0 * x[t] * (1 - x[t])\n",
    "    return np.asarray(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "qe.util.tic()\n",
    "qm_cython(0.1, int(10**5))\n",
    "qe.util.toc()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`cimport` pulls in some compile-time information from NumPy\n",
    "\n",
    "`cdef float_t [:] x = x_np_array` creates a memoryview on the NumPy array `x_np_array`\n",
    "\n",
    "the return statement uses `np.asarray(x)` to convert the memoryview back to a NumPy array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The mean value is 0.000000 in 0.007015 secs\n"
     ]
    }
   ],
   "source": [
    "start3 = time.time()\n",
    "qm_cython(0.1, int(10**5))\n",
    "end3 = time.time()\n",
    "print(\"The mean value is %f in %f secs\"\n",
    "     %(np.mean(x), end3-start3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is fast, although still slightly slower than `qm_numba`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Python, Cython? (from Scikit-Learn documentation)\n",
    "\n",
    "When implementing a new algorithm is thus recommended to start implementing it in Python using Numpy and Scipy by taking care of avoiding looping code using the vectorized idioms of those libraries. In practice this means trying to **replace any nested for loops by calls to equivalent Numpy array methods**.\n",
    "\n",
    "Sometimes however an algorithm cannot be expressed efficiently in simple vectorized Numpy code. In this case, the recommended strategy is the following:\n",
    "* **Profile** the Python implementation to find the main bottleneck and isolate it in a dedicated module level function. This function will be reimplemented as a compiled extension module.\n",
    "* If there exists a well maintained C/C++ implementation of the same algorithm that is not too big, you can write a **Cython wrapper** for it and include a copy of the source code of the library in the source tree\n",
    "* Otherwise, write an optimized version of your Python function using **Cython or Numba** directly. \n",
    "* Once the code is optimized (not simple bottleneck spottable by profiling), check whether it is possible to have **coarse grained parallelism** that is amenable to multi-processing "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
